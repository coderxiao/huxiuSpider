
import scrapy
from scrapy.selector import Selector
import sys,re
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor as selink
from scrapy.contrib.spiders import CrawlSpider,Rule

sys.path.append("/home/wx/code/huxiuspider/")

from huxiuspider.items import BookItem

class BookSpider(CrawlSpider):
	name = "books"
	allow_domains = ["huxiu.com"]
	start_urls = ["http://www.huxiu.com/books"]
	rules = (
		Rule(selink(allow=("books/([0-9]+)\.html",))
			,callback='parse_2'),
	)

	def parse_2(self,response):
		for sel in response.xpath("//div[@class='clearfix mod-b mod-list-book']"):
			item = BookItem()
			#sel = unicode(sel,'UTF-8')
			item["title"] = sel.xpath("//ul[@class='clearfix ul-list']/li[1]/i/text()").extract()
			#item["descript"] = sel.xpath("//div[contains(@class,'summary')]/text()").extract()
			#item["link"] = sel.xpath("div/h4/a/@href").extract()
			
			yield item